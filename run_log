/home/ron/anaconda3/envs/cAgentCombat/bin/python /snap/pycharm-professional/current/plugins/python/helpers/pydev/pydevconsole.py --mode=client --port=42327
import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/home/ron/git/ctf_SingleAgentCombat'])
PyDev console: starting.
Python 3.8.6 | packaged by conda-forge | (default, Oct  7 2020, 19:08:05)
[GCC 7.5.0] on linux
runfile('/home/ron/git/ctf_SingleAgentCombat/Arena/plan_anti_policy.py', wdir='/home/ron/git/ctf_SingleAgentCombat/Arena')
--------------------
 Plan anti policy to the  easy  agent ....
Finished iter 0/100, max_diff = 250.9999314248716
Finished iter 1/100, max_diff = 230.13653795857425
Finished iter 2/100, max_diff = 208.49006899491616
Finished iter 3/100, max_diff = 177.68223390088863
Finished iter 4/100, max_diff = 146.496643884567
Finished iter 5/100, max_diff = 118.4588568317391
Finished iter 6/100, max_diff = 106.53908186813938
Finished iter 7/100, max_diff = 74.29816585326157
Finished iter 8/100, max_diff = 56.79890581923749
Finished iter 9/100, max_diff = 33.48870738076039
Finished iter 10/100, max_diff = 26.240013438299144
Finished iter 11/100, max_diff = 21.76032667054966
Finished iter 12/100, max_diff = 13.467090497789926
Finished iter 13/100, max_diff = 8.469322782355007
Finished iter 14/100, max_diff = 5.246482415878532
Finished iter 15/100, max_diff = 2.480829602599357
Finished iter 16/100, max_diff = 1.6470919852911408
Finished iter 17/100, max_diff = 0.9385805090329029
Finished iter 18/100, max_diff = 0.4714862505262545
Finished iter 19/100, max_diff = 0.25094968020917463
Finished iter 20/100, max_diff = 0.1555820849197005
Finished iter 21/100, max_diff = 0.07306522063615262
Finished iter 22/100, max_diff = 0.0372552474933201
Finished iter 23/100, max_diff = 0.017373486650228642
Finished iter 24/100, max_diff = 0.007831095818701783
Finished iter 25/100, max_diff = 0.003506984805270008
Finished iter 26/100, max_diff = 0.001563705316058872
--------------------
Finished learning the  easy  agent in  00 hours, 28 minutes and 52 seconds
--------------------
 Plan anti policy to the  medium  agent ....
Finished iter 0/100, max_diff = 250.99997807774525
Finished iter 1/100, max_diff = 230.29946793190655
Finished iter 2/100, max_diff = 200.93008074790646
Finished iter 3/100, max_diff = 167.0766038814598
Finished iter 4/100, max_diff = 136.13716025142176
Finished iter 5/100, max_diff = 106.77533937269868
Finished iter 6/100, max_diff = 94.51547251827017
Finished iter 7/100, max_diff = 33.278599273400104
Finished iter 8/100, max_diff = 23.010856450995178
Finished iter 9/100, max_diff = 15.716482310752589
Finished iter 10/100, max_diff = 11.302126163545775
Finished iter 11/100, max_diff = 6.5821132814631085
Finished iter 12/100, max_diff = 5.276140100511796
Finished iter 13/100, max_diff = 3.0363716352825634
Finished iter 14/100, max_diff = 1.6772152624163112
Finished iter 15/100, max_diff = 0.8368138665896794
Finished iter 16/100, max_diff = 0.4319426153598869
Finished iter 17/100, max_diff = 0.21547791669819105
Finished iter 18/100, max_diff = 0.12503032300922712
Finished iter 19/100, max_diff = 0.06899000503763375
Finished iter 20/100, max_diff = 0.03701010920708825
Finished iter 21/100, max_diff = 0.019703048282224245
Finished iter 22/100, max_diff = 0.01017872839774725
Finished iter 23/100, max_diff = 0.005101714458476181
Finished iter 24/100, max_diff = 0.0026584983925772576
Finished iter 25/100, max_diff = 0.0014554675534981243
--------------------
Finished learning the  medium  agent in  00 hours, 56 minutes and 50 seconds
--------------------
 Plan anti policy to the  hard  agent ....
Finished iter 0/100, max_diff = 250.99996510451322
Finished iter 1/100, max_diff = 230.22264292954097
Finished iter 2/100, max_diff = 198.60544042782712
Finished iter 3/100, max_diff = 167.02836160104494
Finished iter 4/100, max_diff = 108.93282756298957
Finished iter 5/100, max_diff = 80.92868925634613
Finished iter 6/100, max_diff = 45.97375438449495
Finished iter 7/100, max_diff = 24.818820540316395
Finished iter 8/100, max_diff = 20.43805888707763
Finished iter 9/100, max_diff = 13.950920769090985
Finished iter 10/100, max_diff = 9.99793405083512
Finished iter 11/100, max_diff = 6.537507503944582
Finished iter 12/100, max_diff = 4.193698168501868
Finished iter 13/100, max_diff = 2.5145301690297117
Finished iter 14/100, max_diff = 1.466577926030709
Finished iter 15/100, max_diff = 1.0587610243511563
Finished iter 16/100, max_diff = 0.505401045951487
Finished iter 17/100, max_diff = 0.24387327796385705
Finished iter 18/100, max_diff = 0.11411903909257148
Finished iter 19/100, max_diff = 0.05400282793792144
Finished iter 20/100, max_diff = 0.0304242828931649
Finished iter 21/100, max_diff = 0.020466906278784336
Finished iter 22/100, max_diff = 0.015216832081250686
Finished iter 23/100, max_diff = 0.01239921451031023
Finished iter 24/100, max_diff = 0.009358676870647287
Finished iter 25/100, max_diff = 0.006854490453775952
Finished iter 26/100, max_diff = 0.005004636316883193
Finished iter 27/100, max_diff = 0.003653556057344076
Finished iter 28/100, max_diff = 0.002667348774423317
Finished iter 29/100, max_diff = 0.0019474325599588838
--------------------
Finished learning the  hard  agent in  01 hours, 28 minutes and 56 seconds
